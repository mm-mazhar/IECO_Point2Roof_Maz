{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pW2Q-6KDTafx"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# \"\"\"\n",
        "# inference.ipynb\n",
        "# Created on Oct Sept 30, 2024\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wSGwQXXTh94"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-K5SH1mWPzL",
        "outputId": "b1c669e5-abc3-4a24-9c02-6d3f3f0d1ed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t_nf8MjEgeY6"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy==1.19.5 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sde-UNXsTmbW"
      },
      "source": [
        "### CUDA and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR_SY7Hgn3uK",
        "outputId": "8ddfa17d-bfe4-4522-9b55-f55819974d15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python Version | 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n",
            "PyTorch Version | 2.5.0+cu121\n",
            "CUDA available | True\n",
            "CUDA device count | 1\n",
            "Current device | 0\n",
            "Using CUDA device: Tesla T4\n",
            "\n",
            "GPU INFORMATION\n",
            "Wed Oct 30 14:51:40 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "\n",
            "MEMORY INFORMATION\n",
            "Your runtime has 13.6 GB of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "# Check CUDA availability\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import os\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "print(f\"Python Version | {sys.version}\")\n",
        "print(f\"PyTorch Version | {torch.__version__}\")\n",
        "\n",
        "print(\"CUDA available |\", torch.cuda.is_available())\n",
        "print(\"CUDA device count |\", torch.cuda.device_count())\n",
        "print(\"Current device |\", torch.cuda.current_device())\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# GPU INFORMATION\n",
        "print(\"\\nGPU INFORMATION\")\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(f\"{gpu_info}\")\n",
        "\n",
        "# MEMORY INFORMATION\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print(\"\\nMEMORY INFORMATION\")\n",
        "print('Your runtime has {:.1f} GB of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "\n",
        "\n",
        "# from path import Path\n",
        "# from os.path import exists\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.spatial.distance\n",
        "import math\n",
        "import random\n",
        "from pprint import pformat\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# sys.path.append(root_dir)\n",
        "\n",
        "# Set the seed for Python's random module\n",
        "random.seed(42)\n",
        "\n",
        "# Set the seed for NumPy\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwZDfsG5U4Af"
      },
      "source": [
        "### Setup Point2Roof"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIhhELcIZT-W",
        "outputId": "b63b178c-f119-4cb5-ace5-de6a318d878d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPO | /content/drive/MyDrive/ColabNotebooks/IECO/point2roof/POINT2ROOF\n"
          ]
        }
      ],
      "source": [
        "PROJ_DIR = \"/content/drive/MyDrive/ColabNotebooks/IECO/point2roof\"\n",
        "REPO = os.path.join(PROJ_DIR, \"POINT2ROOF\")\n",
        "print(f\"REPO | {REPO}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfXjrHAuUz1a",
        "outputId": "490e9fd8-7c33-4023-ca10-940b683665e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path '/content/drive/MyDrive/ColabNotebooks/IECO/point2roof/POINT2ROOF' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/ColabNotebooks/IECO/point2roof/POINT2ROOF\n",
            "\n",
            "Current Directory | /content/drive/MyDrive/ColabNotebooks/IECO/point2roof/POINT2ROOF\n"
          ]
        }
      ],
      "source": [
        "# %cd /content\n",
        "!git clone https://github.com/mm-mazhar/IECO_Point2Roof_Maz.git {REPO} --quiet\n",
        "%cd {REPO}\n",
        "print(f\"\\nCurrent Directory | {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BguOA09ltP8",
        "outputId": "41f012fe-60e7-4ac0-b923-2623d49200fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/307.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m297.0/307.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ninja --quiet\n",
        "# !pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --quiet\n",
        "# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "CZ1GjlVvAghT"
      },
      "outputs": [],
      "source": [
        "# Navigate to pc_util and rebuild\n",
        "%cd pc_util\n",
        "\n",
        "!python setup.py build_ext --inplace --quiet\n",
        "!python setup.py install --quiet\n",
        "\n",
        "%cd ..\n",
        "\n",
        "####################################################\n",
        "# %cd pc_util\n",
        "\n",
        "# # Build the extension in-place\n",
        "# !python setup.py build_ext --inplace\n",
        "\n",
        "# # Install the package using pip (instead of setup.py install)\n",
        "# !pip install .\n",
        "\n",
        "# %cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiKqDIt4VUo8"
      },
      "source": [
        "### Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "XYZ_FILE = \"0dcbf0e7d298b9967fdca389c394133e18d7e4b1\"\n",
        "POINT_FILE: str = os.path.join(PROJ_DIR, \"dataset_colob\", \"points\", XYZ_FILE, \"points.xyz\")\n",
        "MODEL_CONFIG: str = os.path.join(REPO, \"model_cfg.yaml\")                      \n",
        "INFERENCE_DIR: str = os.path.join(REPO, \"inference_output\")\n",
        "CHECKPOINT: str = \"./checkpoint_epoch_90.pth\"\n",
        "\n",
        "\n",
        "print(f\"POINT_FILE | {POINT_FILE}\")\n",
        "print(f\"MODEL_CONFIG | {MODEL_CONFIG}\")\n",
        "print(f\"INFERENCE_DIR | {INFERENCE_DIR}\")\n",
        "print(f\"CHECKPOINT | {CHECKPOINT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmYj6hI_DcAC",
        "outputId": "2eae8fd0-af91-4c70-8fda-3484ef85cd8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-10-30 14:52:04,204   INFO  **********************Start logging**********************\n",
            "2024-10-30 14:52:04,648   INFO  data_path        /content/drive/MyDrive/ColabNotebooks/IECO/point2roof/dataset_colob\n",
            "2024-10-30 14:52:04,648   INFO  cfg_file         ./model_cfg.yaml\n",
            "2024-10-30 14:52:04,649   INFO  batch_size       1\n",
            "2024-10-30 14:52:04,649   INFO  gpu              0\n",
            "2024-10-30 14:52:04,650   INFO  test_tag         test_run_colab\n",
            "2024-10-30 14:52:04,650   INFO  \n",
            "cfg.DATA = edict()\n",
            "2024-10-30 14:52:04,650   INFO  cfg.DATA.NPOINT: 1024\n",
            "2024-10-30 14:52:04,650   INFO  \n",
            "cfg.MODEL = edict()\n",
            "2024-10-30 14:52:04,650   INFO  \n",
            "cfg.MODEL.PointNet2 = edict()\n",
            "2024-10-30 14:52:04,651   INFO  cfg.MODEL.PointNet2.PosRadius: 0.15\n",
            "2024-10-30 14:52:04,651   INFO  \n",
            "cfg.MODEL.PointNet2.LossWeight = edict()\n",
            "2024-10-30 14:52:04,651   INFO  cfg.MODEL.PointNet2.LossWeight.cls_weight: 1.0\n",
            "2024-10-30 14:52:04,651   INFO  cfg.MODEL.PointNet2.LossWeight.reg_weight: 1.0\n",
            "2024-10-30 14:52:04,651   INFO  \n",
            "cfg.MODEL.ClusterRefineNet = edict()\n",
            "2024-10-30 14:52:04,652   INFO  cfg.MODEL.ClusterRefineNet.ScoreThresh: 0.5\n",
            "2024-10-30 14:52:04,652   INFO  cfg.MODEL.ClusterRefineNet.MatchRadius: 0.2\n",
            "2024-10-30 14:52:04,652   INFO  \n",
            "cfg.MODEL.ClusterRefineNet.Cluster = edict()\n",
            "2024-10-30 14:52:04,652   INFO  cfg.MODEL.ClusterRefineNet.Cluster.eps: 0.05\n",
            "2024-10-30 14:52:04,652   INFO  cfg.MODEL.ClusterRefineNet.Cluster.min_pts: 5\n",
            "2024-10-30 14:52:04,653   INFO  \n",
            "cfg.MODEL.ClusterRefineNet.RefineSA = edict()\n",
            "2024-10-30 14:52:04,653   INFO  cfg.MODEL.ClusterRefineNet.RefineSA.Radii: [0.1, 0.2]\n",
            "2024-10-30 14:52:04,653   INFO  cfg.MODEL.ClusterRefineNet.RefineSA.Nsamples: [16, 16]\n",
            "2024-10-30 14:52:04,653   INFO  cfg.MODEL.ClusterRefineNet.RefineSA.MLPs: [[128, 128], [128, 128]]\n",
            "2024-10-30 14:52:04,653   INFO  \n",
            "cfg.MODEL.ClusterRefineNet.LossWeight = edict()\n",
            "2024-10-30 14:52:04,653   INFO  cfg.MODEL.ClusterRefineNet.LossWeight.reg_weight: 1.0\n",
            "2024-10-30 14:52:04,653   INFO  \n",
            "cfg.MODEL.EdgeAttentionNet = edict()\n",
            "2024-10-30 14:52:04,654   INFO  \n",
            "cfg.MODEL.EdgeAttentionNet.LossWeight = edict()\n",
            "2024-10-30 14:52:04,654   INFO  cfg.MODEL.EdgeAttentionNet.LossWeight.cls_weight: 1.0\n",
            "2024-10-30 14:52:04,654   INFO  cfg.ROOT_DIR: /content/drive/MyDrive/ColabNotebooks/IECO/point2roof/POINT2ROOF\n",
            "2024-10-30 14:52:05,062   INFO  Total samples: 5\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "2024-10-30 14:52:05,363   INFO  ==> Loading parameters from checkpoint\n",
            "/content/drive/MyDrive/ColabNotebooks/IECO/point2roof/POINT2ROOF/model/model_utils.py:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename)\n",
            "2024-10-30 14:52:13,396   INFO  ==> Done\n",
            "2024-10-30 14:52:13,397   INFO  **********************Start testing**********************\n",
            "2024-10-30 14:52:13,398   INFO  RoofNet(\n",
            "  (keypoint_det_net): PointNet2(\n",
            "    (sa1): PointNetSAModule(\n",
            "      (groupers): ModuleList(\n",
            "        (0): QueryAndGroup()\n",
            "      )\n",
            "      (mlps): ModuleList(\n",
            "        (0): Conv2ds(\n",
            "          (conv1): Conv2dBN(\n",
            "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv): Conv2d(6, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (conv2): Conv2dBN(\n",
            "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (conv3): Conv2dBN(\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (sa2): PointNetSAModule(\n",
            "      (groupers): ModuleList(\n",
            "        (0): QueryAndGroup()\n",
            "      )\n",
            "      (mlps): ModuleList(\n",
            "        (0): Conv2ds(\n",
            "          (conv1): Conv2dBN(\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv): Conv2d(67, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (conv2): Conv2dBN(\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (conv3): Conv2dBN(\n",
            "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (sa3): PointNetSAModule(\n",
            "      (groupers): ModuleList(\n",
            "        (0): QueryAndGroup()\n",
            "      )\n",
            "      (mlps): ModuleList(\n",
            "        (0): Conv2ds(\n",
            "          (conv1): Conv2dBN(\n",
            "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (conv2): Conv2dBN(\n",
            "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (conv3): Conv2dBN(\n",
            "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (sa4): PointNetSAModule(\n",
            "      (groupers): ModuleList(\n",
            "        (0): QueryAndGroup()\n",
            "      )\n",
            "      (mlps): ModuleList(\n",
            "        (0): Conv2ds(\n",
            "          (conv1): Conv2dBN(\n",
            "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (conv2): Conv2dBN(\n",
            "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (conv3): Conv2dBN(\n",
            "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (fp4): PointNetFPModule(\n",
            "      (mlp): Conv2ds(\n",
            "        (conv1): Conv2dBN(\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (conv2): Conv2dBN(\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (fp3): PointNetFPModule(\n",
            "      (mlp): Conv2ds(\n",
            "        (conv1): Conv2dBN(\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (conv2): Conv2dBN(\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (fp2): PointNetFPModule(\n",
            "      (mlp): Conv2ds(\n",
            "        (conv1): Conv2dBN(\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (conv2): Conv2dBN(\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (fp1): PointNetFPModule(\n",
            "      (mlp): Conv2ds(\n",
            "        (conv1): Conv2dBN(\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (conv2): Conv2dBN(\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (conv3): Conv2dBN(\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (shared_fc): Conv1dBN(\n",
            "      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
            "    )\n",
            "    (drop): Dropout(p=0.5, inplace=False)\n",
            "    (offset_fc): Conv1d(128, 3, kernel_size=(1,), stride=(1,))\n",
            "    (cls_fc): Conv1d(128, 1, kernel_size=(1,), stride=(1,))\n",
            "    (cls_loss_func): SigmoidBCELoss()\n",
            "    (reg_loss_func): WeightedSmoothL1Loss()\n",
            "  )\n",
            "  (cluster_refine_net): ClusterRefineNet(\n",
            "    (matcher): HungarianMatcher()\n",
            "    (fea_refine_module): StackSAModuleMSG(\n",
            "      (groupers): ModuleList(\n",
            "        (0-1): 2 x QueryAndGroup()\n",
            "      )\n",
            "      (mlps): ModuleList(\n",
            "        (0-1): 2 x Sequential(\n",
            "          (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (shared_fc): LinearBN(\n",
            "      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv): Linear(in_features=256, out_features=128, bias=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.5, inplace=False)\n",
            "    (offset_fc): Linear(in_features=128, out_features=3, bias=True)\n",
            "    (reg_loss_func): WeightedSmoothL1Loss()\n",
            "  )\n",
            "  (edge_att_net): EdgeAttentionNet(\n",
            "    (att_layer): PairedPointAttention(\n",
            "      (edge_att1): Sequential(\n",
            "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (4): Sigmoid()\n",
            "      )\n",
            "      (edge_att2): Sequential(\n",
            "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (4): Sigmoid()\n",
            "      )\n",
            "      (fea_fusion_layer): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (shared_fc): LinearBN(\n",
            "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv): Linear(in_features=256, out_features=256, bias=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.5, inplace=False)\n",
            "    (cls_fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "    (cls_loss_func): SigmoidBCELoss()\n",
            "  )\n",
            ")\n",
            "test:   0% 0/5 [00:00<?, ?it/s]file_path | /435667\n",
            "file_path | /415772\n",
            "file_path | /179984\n",
            "file_path | /31289\n",
            "file_path | /69442\n",
            "test:   0% 0/5 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ColabNotebooks/IECO/point2roof/POINT2ROOF/./test.py\", line 65, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/ColabNotebooks/IECO/point2roof/POINT2ROOF/./test.py\", line 61, in main\n",
            "    test_model(net, test_loader, logger)\n",
            "  File \"/content/drive/MyDrive/ColabNotebooks/IECO/point2roof/POINT2ROOF/test_util.py\", line 52, in test_model\n",
            "    batch = next(dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1465, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1491, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 715, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n",
            "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/drive/MyDrive/ColabNotebooks/IECO/point2roof/POINT2ROOF/dataset/roofn3d_dataset.py\", line 68, in __getitem__\n",
            "    points = read_pts(file_path + '/points.xyz')\n",
            "  File \"/content/drive/MyDrive/ColabNotebooks/IECO/point2roof/POINT2ROOF/dataset/roofn3d_dataset.py\", line 8, in read_pts\n",
            "    with open(pts_file, 'r') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/435667/points.xyz'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python ./inference.py --file_path {POINT_FILE} --cfg_file {MODEL_CONFIG} --batch_size 1 --gpu 0 --output_dir {INFERENCE_DIR} --ckpt_file {CHECKPOINT}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
